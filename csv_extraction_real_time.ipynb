{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8f5f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and processing the dataset...\n",
      "Training the model...\n",
      "Accuracy of the model: 99.48%\n",
      "Collecting data for calibration...\n",
      "Testing interrupted by User. STATUS: not empty\n"
     ]
    }
   ],
   "source": [
    "import serial                            # imports the 'pyserial' library. This library allows Python to communicate with the Serial Ports\n",
    "import pandas as pd                      # imports the 'pandas' library which is used for handling data tables (CSV in our case)\n",
    "import numpy as np                       # imports the 'numpy' library which is used for fast mathematical operations\n",
    "import re                                # imports the 're' (Regular Expression) library. We use it to find patterns (numbers in our case) inside text \n",
    "from collections import deque            # imports the 'deque' (double-ended queue) data structure to use as an optimized list for buffers\n",
    "import time                              # imports the 'time' library which provides time-related functions\n",
    "\n",
    "# imports specific tool from 'sklearn' (Scikit-Learn) Machine Learning library\n",
    "from sklearn.model_selection import train_test_split            # tool to split data into 'training' and 'testing' sets\n",
    "from sklearn.ensemble import RandomForestClassifier             # the ML model we are using (a collection of silly decision trees)\n",
    "from sklearn.metrics import accuracy_score                      # tools to grade the models performance\n",
    "from sklearn.decomposition import PCA                           # tool to help reduce the size of the dataset\n",
    "from sklearn.impute import SimpleImputer                        # tool to replace missing data with plausible values\n",
    "from scipy.signal import savgol_filter                          # tool to filter noise and smooth data\n",
    "\n",
    "# Configuration\n",
    "COM_PORT = 'COM4'                             # the COM port where the RX is connected\n",
    "BAUD_RATE = 921600                            # baud rate for serial communication (matches the RX configuration)\n",
    "training_file = \"filtered_csi_dataset.csv\"    # the name of the file used to train the model before seeing it's capabilities in real-time\n",
    "\n",
    "print(f\"Loading and processing the dataset...\")\n",
    "\n",
    "try:\n",
    "    # reads the CSV file into a DataFrame (a table structure)\n",
    "    # header = None -> tells pandas there are no column names in the first row\n",
    "    # on_bad_lines = 'skip' -> ignores corrupted rows instead of crashing the program\n",
    "    # engine = 'python' -> uses the Python parsing engine\n",
    "    df = pd.read_csv(training_file, header = None, on_bad_lines = 'skip', engine = 'python')\n",
    "\n",
    "    # standard error handling\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: file {training_file} not found.\")\n",
    "    raise   # stops the program if the file is missing\n",
    "\n",
    "# y_raw contains the 'answers' (0 for empty, 1 for person in room)\n",
    "y_raw = df.iloc[:,0].values\n",
    "\n",
    "# X_raw contains the 'questions' (the raw CSI data)\n",
    "X_raw = df.iloc[:,4:].values\n",
    "\n",
    "# the raw data is interleaved (real, imaginary, real, imaginary...)\n",
    "# we extract the real parts by taking every 2nd column starting from index 0\n",
    "# we extract the imaginary parts by taking every 2nd column starting from index 1\n",
    "real_parts = X_raw[:, 0::2]\n",
    "imaginary_parts = X_raw[:, 1::2]\n",
    "\n",
    "# we calculate the amplitude (signal strength) using Pythagorean theorem\n",
    "# sqrt(real^2 + imaginary^2)\n",
    "X_amp = np.sqrt(real_parts**2 + imaginary_parts**2)\n",
    "\n",
    "# handles missing values (NaNs) caused by errors by replacing them with thea mean of the column\n",
    "imputer = SimpleImputer(strategy = 'mean')\n",
    "\n",
    "# apply imputation to our data\n",
    "X_amp = imputer.fit_transform(X_amp)\n",
    "\n",
    "# apply Savitzky-Golay filter across time (axis = 0 -> rows), not across subcarriers\n",
    "X_amp = savgol_filter(X_amp, window_length = 11, polyorder = 3, axis = 0)\n",
    "\n",
    "# calculate the average signal strength for each column (axis = 0) across the entire dataset\n",
    "X_mean = np.mean(X_amp, axis = 0)\n",
    "\n",
    "# calculate the standard deviation to measure how much the signal usually fluctuates\n",
    "X_std = np.std(X_amp, axis = 0)\n",
    "\n",
    "# apply Z-score standardization -> center data around 0 and scale it (add a small epsilon to avoid division by 0)\n",
    "X_amp = (X_amp - X_mean) / (X_std + 0.00001)\n",
    "\n",
    "# keep 95% information\n",
    "pca = PCA(n_components = 0.95)\n",
    "\n",
    "# reduce the dimension of the data\n",
    "X_amp = pca.fit_transform(X_amp)\n",
    "\n",
    "# calculate the absolute difference between the current row and the previous row to detect motion\n",
    "# prepend = X_amp[0:1] ensures the result has the same number of rows as the input\n",
    "delta = np.abs(np.diff(X_amp, axis = 0, prepend = X_amp[0:1]))\n",
    "\n",
    "# rolling standard deviation for small movements detection\n",
    "# we calculate the standard deviation for the PCA features over the last 20 packets\n",
    "# .fillna(0) handles the first 20 rows that won't have enough data\n",
    "rolling_std = pd.DataFrame(X_amp).rolling(window = 20).std().fillna(0).values\n",
    "\n",
    "# combines the amplitude (a static feature) with delta (a dynamic feature) and rolling_std (a dynamic feature for small movements) into a large table\n",
    "X_final = np.hstack([X_amp, delta, rolling_std])\n",
    "print(f\"Training the model...\")\n",
    "\n",
    "# here we will split the data into two parts:\n",
    "# X_train, y_train (95%) is used to train the model\n",
    "# X_test, y_test (5%) is used to test the model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_raw, test_size = 0.05)\n",
    "\n",
    "# we create a 'RandomForest' which consists of 50 decision trees (n_estimators = 50)\n",
    "model = RandomForestClassifier(n_estimators = 50)\n",
    "\n",
    "# the model looks at X_train (CSI patterns) and learns to associate them with y_train (labels)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# we ask the model to predict the labels for the test data (X_test)\n",
    "# the model will not see the real answers (y_test) just yet\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# we compare the model's guesses (y_pred) with the real answers (y_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of the model: {accuracy * 100:.2f}%\")\n",
    "\n",
    "ser = None # initialize the serial connection variable as 'None' (empty)\n",
    "\n",
    "try:       # the 'try' block let's us test a block of code for errors\n",
    "    # Initialize Serial Connection (opens the specific serial port at the specified speed, 'timeout = 0.1' means it will wait 100ms for data before moving on)\n",
    "    ser = serial.Serial(COM_PORT, BAUD_RATE, timeout = 0.1)\n",
    "    \n",
    "    ser.reset_input_buffer()   # clear the buffer to get rid of old data\n",
    "    \n",
    "    probability_buffer = []    # list to save recent probability predictions for optimizations\n",
    "    buffer_size = 10           # number of recent predictions to average (determines reaction speed)\n",
    "\n",
    "    min_threshold = 0.70       # decision threshold (min)     \n",
    "    max_threshold = 0.85       # decision threshold (max) \n",
    "    person_detected = False    # defines a state variable outside the loop\n",
    "\n",
    "    previous_pca = None        # variable store previous PCA vector for delta calculation\n",
    "\n",
    "    SG_buffer = deque(maxlen = 11)  # buffer for Savitzky-Golay. It is used to store the last 11 packets to apply the filter for live data\n",
    "    std_buffer = deque(maxlen = 20) # buffer for rolling standard deviation. It is used to store the last 20 PCA features and looks for movements\n",
    "\n",
    "    print(f\"Collecting data for calibration...\")\n",
    "\n",
    "    # we collect data when the room is empty for like 30 seconds (we do that, so our model is able to predict if the room is empty or not regardless of the objects/furniture in the room and if they changed position since we collected data for training)\n",
    "    calibration_data = []\n",
    "\n",
    "    # we save the time the calibration process started\n",
    "    start_calibration_time = time.time()\n",
    "\n",
    "    # this gives us enough time to leave the room\n",
    "    time.sleep(20)\n",
    "\n",
    "    # we collect data for 30 seconds to learn the \"empty room\" state\n",
    "    while time.time() - start_calibration_time < 30:\n",
    "        try: \n",
    "            raw_line = ser.readline()\n",
    "            if not raw_line: continue\n",
    "\n",
    "            line = raw_line.decode('utf-8', errors = 'ignore').strip()\n",
    "\n",
    "            if line.startswith(\"[CSI DATA]\"):\n",
    "                numbers_found = re.findall(r'-?\\d+', line)\n",
    "\n",
    "                if len(numbers_found) > 3 and numbers_found[2] == '384':\n",
    "                    csi_raw = [int(x) for x in numbers_found[-384:]]\n",
    "\n",
    "                    if len(csi_raw) >= 382:\n",
    "                        csi_np = np.array(csi_raw)\n",
    "\n",
    "                        real_part = csi_np[0::2]\n",
    "                        imaginary_part = csi_np[1::2]\n",
    "      \n",
    "                        ampl = np.sqrt(real_part**2 + imaginary_part**2)\n",
    "                        \n",
    "                        if ampl.shape[0] > X_mean.shape[0]:\n",
    "                            ampl = ampl[:X_mean.shape[0]]\n",
    "\n",
    "                        ampl = (ampl - X_mean) / (X_std + 0.00001)\n",
    "\n",
    "                        # store this \"empty room\" packet in our list\n",
    "                        calibration_data.append(ampl)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    # check if the list is empty        \n",
    "    if len(calibration_data) > 0:\n",
    "        # calculate the average of the \"empty room\" signals (axis = 0 -> rows)\n",
    "        # this \"baseline_static\" represents the furniture, walls, and static environment\n",
    "        baseline_static = np.mean(calibration_data, axis = 0)\n",
    "    else:\n",
    "        baseline_static = 0\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            ser.reset_input_buffer()   # clear the serial buffer to get rid of old data\n",
    "            raw_line = ser.readline()  # read the most recent line of data available\n",
    "\n",
    "            if not raw_line: continue\n",
    "            \n",
    "            # decodes the bytes to text (utf-8) and gets rid of unwanted spaces (.strip())\n",
    "            # errors = 'ignore' is used to ignore corrupted characters\n",
    "            line = raw_line.decode('utf-8', errors = 'ignore').strip()\n",
    "\n",
    "            # check if the row starts with the key text we set\n",
    "            if line.startswith(\"[CSI DATA]\"):\n",
    "                # re.findall(r'-?\\d+',line) scans the entire line of text\n",
    "                # r'-?\\d+' -> searches for any group of digits (\\d+)\n",
    "                numbers_found = re.findall(r'-?\\d+', line)\n",
    "\n",
    "                # we check if the length of the CSI string is 384, if it is, we keep it\n",
    "                if len(numbers_found) > 3 and numbers_found[2] == '384':\n",
    "                    # [-384] -> we grab the last 384 numbers in the line (where the important data is)\n",
    "                    csi_raw = [int(x) for x in numbers_found[-384:]]\n",
    "\n",
    "                    # ignores the bad lines thus filtering the data\n",
    "                    if len(csi_raw) >= 382:\n",
    "                        # converts the Python list into a NumPy array (for time optimization)\n",
    "                        csi_np = np.array(csi_raw)\n",
    "\n",
    "                        # the raw data is interleaved (real, imaginary, real, imaginary...)\n",
    "                        # we extract the real parts by taking every 2nd column starting from index 0\n",
    "                        # we extract the imaginary parts by taking every 2nd column starting from index 1\n",
    "                        real_part = csi_np[0::2]\n",
    "                        imaginary_part = csi_np[1::2]\n",
    "                        \n",
    "                        # we calculate the amplitude (signal strength) using Pythagorean theorem\n",
    "                        # sqrt(real^2 + imaginary^2)\n",
    "                        ampl = np.sqrt(real_part**2 + imaginary_part**2)\n",
    "                        \n",
    "                        # ensures the live packet has the same number of columns as the training data\n",
    "                        if ampl.shape[0] > X_mean.shape[0]:\n",
    "                            ampl = ampl[:X_mean.shape[0]]\n",
    "\n",
    "                        # standardize using the mean and std learned during training\n",
    "                        ampl = (ampl - X_mean) / (X_std + 0.00001)\n",
    "\n",
    "                        # we subtract the baseline (furniture, walls, objects, etc.) from the current signal \n",
    "                        # if room is empty, this value is approximately 0. If room is not empty, this value is greater than 0.\n",
    "                        ampl = ampl - baseline_static\n",
    "\n",
    "                        # add amplitude to rolling buffer for smoothing \n",
    "                        SG_buffer.append(ampl)\n",
    "\n",
    "                        # wait until we have enough packets in our buffer to filter\n",
    "                        if len(SG_buffer) < 11: continue\n",
    "                            \n",
    "                        # converts buffer to 2D array\n",
    "                        batch_of_data = np.array(SG_buffer)  \n",
    "\n",
    "                        # apply filter to the previously converted array\n",
    "                        batch_of_smoothed_data = savgol_filter(batch_of_data, window_length = 11, polyorder = 3, axis = 0)\n",
    "\n",
    "                        # takes the most recent smoothed packet (last row)\n",
    "                        current_smoothed_data = batch_of_smoothed_data[-1].reshape(1,-1)  \n",
    "\n",
    "                        current_pca = pca.transform(current_smoothed_data)\n",
    "\n",
    "                        if previous_pca is None:\n",
    "                            delta = np.zeros_like(current_pca)          # since we have no history, for the first packet delta will be 0\n",
    "                        else:\n",
    "                            delta = np.abs(current_pca - previous_pca)  # calculate the absolute difference between curremt packet and the previous one\n",
    "                        \n",
    "                        previous_pca = current_pca                      # update history\n",
    "\n",
    "                        # we append the flattened array to the deque so we can calculate standard deviation easier\n",
    "                        std_buffer.append(current_pca.flatten())\n",
    "\n",
    "                        # wait for std_buffer to fill with 20 packets\n",
    "                        if len(std_buffer) < 20: continue\n",
    "\n",
    "                        # calculate standard deviation of the buffer across time (axis = 0)\n",
    "                        current_std = np.std(np.array(std_buffer), axis = 0).reshape(1,-1)\n",
    "\n",
    "                        # combine pca and delta to match training data format\n",
    "                        features = np.hstack([current_pca, delta, current_std])\n",
    "\n",
    "                        # reshape to (1, n_features) to make it a 2D array (1 is the number of rows, -1 means that the number of columns is unknown)\n",
    "                        features_ready = features.reshape(1,-1)\n",
    "\n",
    "                        # get the probability that the room is not empty\n",
    "                        probability = model.predict_proba(features_ready)[0][1]\n",
    "                        \n",
    "                        # adding the probability to the circular buffer\n",
    "                        probability_buffer.append(probability)\n",
    "                        if len(probability_buffer) > buffer_size:\n",
    "                            probability_buffer.pop(0) # remove the oldest value to maintain buffer size\n",
    "\n",
    "                        # calculate the median score (good filter)\n",
    "                        confidence = np.median(probability_buffer)  \n",
    "\n",
    "                        # hysteresis logic for more accurate predictions\n",
    "                        if person_detected:\n",
    "                            # switch to 'empty' if the score drops below our threshold\n",
    "                            if confidence < min_threshold:\n",
    "                                person_detected = False\n",
    "                                info = \"empty    \"\n",
    "                            else:\n",
    "                                info = \"not empty\"     \n",
    "                        else:\n",
    "                            # switch to 'not empty' if score goes above our threshold           \n",
    "                            if confidence > max_threshold:\n",
    "                                person_detected = True\n",
    "                                info = \"not empty\"\n",
    "                            else:\n",
    "                                info = \"empty    \"\n",
    "                        \n",
    "                        print(f\"RSSI: {numbers_found[1]}dBm, CONFIDENCE: {confidence:.4f}, STATUS: {info}\", end = '\\r')    \n",
    "        except (ValueError, IndexError):\n",
    "            continue\n",
    "\n",
    "# the 'except' block is used for error handling outside the loop         \n",
    "except serial.SerialException as e:\n",
    "    print(f\"Error: {e}\")                      # if the port is busy or the cable is unplugged\n",
    "except KeyboardInterrupt:\n",
    "    print(f\"Testing interrupted by User.\")    # if we press 'Interrupt' in Jupyter\n",
    "\n",
    "# the 'finally' block will be executed regardless if the try block raises an error or not\n",
    "finally:\n",
    "    if ser is not None and ser.is_open: # check if the serial connection was opened\n",
    "        ser.close()                     # if it was opened, we will close the USB port"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
